{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIom1X-v0TGc"
   },
   "source": [
    "# Assignment - Basic Pandas\n",
    "<sup>Created by Natawut Nupairoj, Department of Computer Engineering, Chulalongkorn University</sup>\n",
    "\n",
    "Using pandas to explore youtube trending data from GB (GBvideos.csv and GB_category_id.json) and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "_ooeQeBn0TGf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNyAGpWT0TGh"
   },
   "source": [
    "To simplify data retrieval process on Colab, we heck if we are in the Colab environment and download data files from a shared drive and save them in folder \"data\".\n",
    "\n",
    "For those using jupyter notebook on the local computer, you can read data directly assuming you save data in the folder \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qro_9JWV0TGi",
    "outputId": "3e7f5c45-98ec-4160-bcc1-1697a048d29b"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !wget https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/datasets/data.tgz -O data.tgz\n",
    "    !tar -xzvf data.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkNi2LHT0TGj"
   },
   "source": [
    "## How many rows are there in the GBvideos.csv after removing duplications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data GBvideos.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "id": "PFzYyW7V0TGj"
   },
   "outputs": [],
   "source": [
    "vdo_df = pd.read_csv('data/GBvideos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check rows and columns info and shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38916 entries, 0 to 38915\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                38916 non-null  object\n",
      " 1   trending_date           38916 non-null  object\n",
      " 2   title                   38916 non-null  object\n",
      " 3   channel_title           38916 non-null  object\n",
      " 4   category_id             38916 non-null  int64 \n",
      " 5   publish_time            38916 non-null  object\n",
      " 6   tags                    38916 non-null  object\n",
      " 7   views                   38916 non-null  int64 \n",
      " 8   likes                   38916 non-null  int64 \n",
      " 9   dislikes                38916 non-null  int64 \n",
      " 10  comment_count           38916 non-null  int64 \n",
      " 11  thumbnail_link          38916 non-null  object\n",
      " 12  comments_disabled       38916 non-null  bool  \n",
      " 13  ratings_disabled        38916 non-null  bool  \n",
      " 14  video_error_or_removed  38916 non-null  bool  \n",
      " 15  description             38304 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "vdo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38916, 16)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicated rows and print out the unique rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38745"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_df_unique = vdo_df.drop_duplicates()\n",
    "vdo_df_unique.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSc2U7HJ0TGk"
   },
   "source": [
    "## How many VDO's that contain at least one record (row) of \"dislikes\" more than \"likes\"?  <font color=red>DO NOT group by the data and make sure that you count only unique title!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the head of rows which have dislikes more than likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "Q0NF1dI40TGk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Bone on Labour HQ</td>\n",
       "      <td>1160</td>\n",
       "      <td>1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>After Show: Did Kate Hudson Date Brad Pitt? | ...</td>\n",
       "      <td>184</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Svjetska ekskluziva: Provala u stan Dejana Lov...</td>\n",
       "      <td>83</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Bone on Labour HQ</td>\n",
       "      <td>1168</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>After Show: Did Kate Hudson Date Brad Pitt? | ...</td>\n",
       "      <td>186</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  likes  dislikes\n",
       "91                                   Bone on Labour HQ   1160      1164\n",
       "110  After Show: Did Kate Hudson Date Brad Pitt? | ...    184       187\n",
       "161  Svjetska ekskluziva: Provala u stan Dejana Lov...     83       108\n",
       "309                                  Bone on Labour HQ   1168      1170\n",
       "327  After Show: Did Kate Hudson Date Brad Pitt? | ...    186       190"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_df_unique[vdo_df_unique['likes'] < vdo_df_unique['dislikes']][['title','likes', 'dislikes']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use aggergate function \"nunique\" to find the unique title which has dislikes more than likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/220_46zj42nfr21hd0l1_ks40000gn/T/ipykernel_45214/3906632881.py:5: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  display(int(title_dislikes_more_likes))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapper = {\n",
    "    'title': 'nunique'\n",
    "}\n",
    "title_dislikes_more_likes = vdo_df_unique[vdo_df_unique['likes'] < vdo_df_unique['dislikes']].agg(mapper)\n",
    "display(int(title_dislikes_more_likes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNxh-5CL0TGk"
   },
   "source": [
    "## How many VDO that are trending on 22 Jan 2018 with comments more than 10,000 comments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use condition \"where trending_data == '18.22.01' and comment_count > 10000\" to find rows and check this head to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "07-y5sNw0TGl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13392</th>\n",
       "      <td>My Horibal Speling</td>\n",
       "      <td>18.22.01</td>\n",
       "      <td>70565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13394</th>\n",
       "      <td>The Smallest Bird you have ever seen</td>\n",
       "      <td>18.22.01</td>\n",
       "      <td>10121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13397</th>\n",
       "      <td>ELDERS REACT TO UGANDAN KNUCKLES MEMES</td>\n",
       "      <td>18.22.01</td>\n",
       "      <td>14099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13398</th>\n",
       "      <td>Primitive Technology: A-frame hut</td>\n",
       "      <td>18.22.01</td>\n",
       "      <td>13839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13411</th>\n",
       "      <td>J. Balvin, Jeon, Anitta - Machika</td>\n",
       "      <td>18.22.01</td>\n",
       "      <td>69932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title trending_date  comment_count\n",
       "13392                      My Horibal Speling      18.22.01          70565\n",
       "13394    The Smallest Bird you have ever seen      18.22.01          10121\n",
       "13397  ELDERS REACT TO UGANDAN KNUCKLES MEMES      18.22.01          14099\n",
       "13398       Primitive Technology: A-frame hut      18.22.01          13839\n",
       "13411       J. Balvin, Jeon, Anitta - Machika      18.22.01          69932"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_selected_df = vdo_df_unique[(vdo_df_unique['trending_date'] == '18.22.01') & (vdo_df_unique['comment_count'] > 10_000)][['title', 'trending_date', 'comment_count']]\n",
    "vdo_selected_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print out the rows which are true from condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_selected_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnBQwfD70TGl"
   },
   "source": [
    "## Which date that has the minimum average number of comments per VDO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group by trending_date then calculate the average of comment_count per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trending_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17.01.12</th>\n",
       "      <td>9528.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.02.12</th>\n",
       "      <td>9077.180905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.03.12</th>\n",
       "      <td>9132.688442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.04.12</th>\n",
       "      <td>9276.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.05.12</th>\n",
       "      <td>9510.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.30.04</th>\n",
       "      <td>18460.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.30.05</th>\n",
       "      <td>23361.103659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.31.01</th>\n",
       "      <td>9318.939698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.31.03</th>\n",
       "      <td>14982.356383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.31.05</th>\n",
       "      <td>22928.368421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               comment_count\n",
       "trending_date               \n",
       "17.01.12         9528.712121\n",
       "17.02.12         9077.180905\n",
       "17.03.12         9132.688442\n",
       "17.04.12         9276.555000\n",
       "17.05.12         9510.740000\n",
       "...                      ...\n",
       "18.30.04        18460.151515\n",
       "18.30.05        23361.103659\n",
       "18.31.01         9318.939698\n",
       "18.31.03        14982.356383\n",
       "18.31.05        22928.368421\n",
       "\n",
       "[205 rows x 1 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_avg_per_dt = vdo_df_unique.groupby('trending_date')[['trending_date', 'comment_count']].mean('comment_count')\n",
    "comment_avg_per_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the minimum average day by using idxmin() then select only value at np.array position 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the date that has the minimum average number of comments per VDO is 17.15.11 or 15-11-2017\n"
     ]
    }
   ],
   "source": [
    "orig_min_avg_comment_dt = (comment_avg_per_dt.idxmin()).values[0]\n",
    "min_avg_comment_dt =  datetime.strptime(orig_min_avg_comment_dt, '%y.%d.%m')\n",
    "formatted_min_avg_comment_dt = min_avg_comment_dt.strftime('%d-%m-%Y')\n",
    "print(f'the date that has the minimum average number of comments per VDO is {orig_min_avg_comment_dt } or {formatted_min_avg_comment_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wL7iTiic0TGl"
   },
   "source": [
    "## Compare \"Sports\" and \"Comady\", how many days that there are more total daily views of VDO in \"Sports\" category than in \"Comady\" category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data/GB_category_id.json into cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('data/GB_category_id.json') as fd:\n",
    "    cat = json.load(fd)\n",
    "\n",
    "cat_list = []\n",
    "for d in cat['items']:\n",
    "    cat_list.append((int(d['id']), d['snippet']['title']))\n",
    "\n",
    "cat_df= pd.DataFrame(cat_list, columns=['id', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inner join vdo_df_unique and cat_df by using key category_id and id respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jw1Y-zhQURU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>John Lewis Christmas Ad 2017 - #MozTheMonster</td>\n",
       "      <td>John Lewis</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-10T07:38:29.000Z</td>\n",
       "      <td>christmas|\"john lewis christmas\"|\"john lewis\"|...</td>\n",
       "      <td>7224515</td>\n",
       "      <td>55681</td>\n",
       "      <td>10247</td>\n",
       "      <td>9479</td>\n",
       "      <td>https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Click here to continue the story and make your...</td>\n",
       "      <td>26</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3s1rvMFUweQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Taylor Swift: …Ready for It? (Live) - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T06:24:44.000Z</td>\n",
       "      <td>SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"Epi...</td>\n",
       "      <td>1053632</td>\n",
       "      <td>25561</td>\n",
       "      <td>2294</td>\n",
       "      <td>2757</td>\n",
       "      <td>https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Musical guest Taylor Swift performs …Ready for...</td>\n",
       "      <td>24</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Eminem - Walk On Water (Audio) ft. Beyoncé</td>\n",
       "      <td>EminemVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10T17:00:03.000Z</td>\n",
       "      <td>Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787420</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Eminem's new track Walk on Water ft. Beyoncé i...</td>\n",
       "      <td>10</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUTEiSjKwJU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Goals from Salford City vs Class of 92 and Fri...</td>\n",
       "      <td>Salford City Football Club</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:30:38.000Z</td>\n",
       "      <td>Salford City FC|\"Salford City\"|\"Salford\"|\"Clas...</td>\n",
       "      <td>27833</td>\n",
       "      <td>193</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>https://i.ytimg.com/vi/PUTEiSjKwJU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Salford drew 4-4 against the Class of 92 and F...</td>\n",
       "      <td>17</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rHwDegptbI4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "      <td>Cute Girl Videos</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T01:45:13.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>9815</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>https://i.ytimg.com/vi/rHwDegptbI4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "      <td>25</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  Jw1Y-zhQURU      17.14.11   \n",
       "1  3s1rvMFUweQ      17.14.11   \n",
       "2  n1WpP7iowLc      17.14.11   \n",
       "3  PUTEiSjKwJU      17.14.11   \n",
       "4  rHwDegptbI4      17.14.11   \n",
       "\n",
       "                                               title  \\\n",
       "0      John Lewis Christmas Ad 2017 - #MozTheMonster   \n",
       "1          Taylor Swift: …Ready for It? (Live) - SNL   \n",
       "2         Eminem - Walk On Water (Audio) ft. Beyoncé   \n",
       "3  Goals from Salford City vs Class of 92 and Fri...   \n",
       "4  Dashcam captures truck's near miss with child ...   \n",
       "\n",
       "                channel_title  category_id              publish_time  \\\n",
       "0                  John Lewis           26  2017-11-10T07:38:29.000Z   \n",
       "1         Saturday Night Live           24  2017-11-12T06:24:44.000Z   \n",
       "2                  EminemVEVO           10  2017-11-10T17:00:03.000Z   \n",
       "3  Salford City Football Club           17  2017-11-13T02:30:38.000Z   \n",
       "4            Cute Girl Videos           25  2017-11-13T01:45:13.000Z   \n",
       "\n",
       "                                                tags     views   likes  \\\n",
       "0  christmas|\"john lewis christmas\"|\"john lewis\"|...   7224515   55681   \n",
       "1  SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"Epi...   1053632   25561   \n",
       "2  Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...  17158579  787420   \n",
       "3  Salford City FC|\"Salford City\"|\"Salford\"|\"Clas...     27833     193   \n",
       "4                                             [none]      9815      30   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0     10247           9479  https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg   \n",
       "1      2294           2757  https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg   \n",
       "2     43420         125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
       "3        12             37  https://i.ytimg.com/vi/PUTEiSjKwJU/default.jpg   \n",
       "4         2             30  https://i.ytimg.com/vi/rHwDegptbI4/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  id         category  \n",
       "0  Click here to continue the story and make your...  26    Howto & Style  \n",
       "1  Musical guest Taylor Swift performs …Ready for...  24    Entertainment  \n",
       "2  Eminem's new track Walk on Water ft. Beyoncé i...  10            Music  \n",
       "3  Salford drew 4-4 against the Class of 92 and F...  17           Sports  \n",
       "4  Dashcam captures truck's near miss with child ...  25  News & Politics  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_df_unique_with_cat = vdo_df_unique.merge(cat_df, left_on='category_id', right_on='id')\n",
    "vdo_df_unique_with_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter category only Sports and Comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     Sports\n",
       "10    Sports\n",
       "18    Comedy\n",
       "26    Sports\n",
       "28    Comedy\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_comedy_df = vdo_df_unique_with_cat[vdo_df_unique_with_cat['category'].isin(['Sports','Comedy'])]\n",
    "sports_comedy_df['category'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group by trending_date and category respectively and select columns views then use unpack() to pivot a level of the index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Sports</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trending_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17.01.12</th>\n",
       "      <td>10889970</td>\n",
       "      <td>9879808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.02.12</th>\n",
       "      <td>13302391</td>\n",
       "      <td>10856461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.03.12</th>\n",
       "      <td>14259944</td>\n",
       "      <td>10875249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.04.12</th>\n",
       "      <td>16617431</td>\n",
       "      <td>11399173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.05.12</th>\n",
       "      <td>19089597</td>\n",
       "      <td>11261410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.30.04</th>\n",
       "      <td>17802688</td>\n",
       "      <td>15114095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.30.05</th>\n",
       "      <td>16427316</td>\n",
       "      <td>5153521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.31.01</th>\n",
       "      <td>14840766</td>\n",
       "      <td>8431519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.31.03</th>\n",
       "      <td>21528161</td>\n",
       "      <td>22546308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.31.05</th>\n",
       "      <td>16743398</td>\n",
       "      <td>6343358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "category         Comedy    Sports\n",
       "trending_date                    \n",
       "17.01.12       10889970   9879808\n",
       "17.02.12       13302391  10856461\n",
       "17.03.12       14259944  10875249\n",
       "17.04.12       16617431  11399173\n",
       "17.05.12       19089597  11261410\n",
       "...                 ...       ...\n",
       "18.30.04       17802688  15114095\n",
       "18.30.05       16427316   5153521\n",
       "18.31.01       14840766   8431519\n",
       "18.31.03       21528161  22546308\n",
       "18.31.05       16743398   6343358\n",
       "\n",
       "[205 rows x 2 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_views = sports_comedy_df.groupby(['trending_date', 'category'])['views'].sum().unstack(level=-1)\n",
    "daily_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum days that there are more total daily views of Sports  than Comady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_views_sports_more_comedy = (daily_views['Sports'] > daily_views['Comedy']).sum()\n",
    "display(int(daily_views_sports_more_comedy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
